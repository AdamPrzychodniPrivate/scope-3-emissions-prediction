{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List, Union\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 # catalog = context.catalog</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>7 catalog.list()                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">8 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m# catalog = context.catalog\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m7 catalog.list()                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m8 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'catalog'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from kedro.framework.context import load_context\n",
    "\n",
    "# context = load_context('pipeline')\n",
    "# catalog = context.catalog\n",
    "\n",
    "\n",
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_rows_with_missing_values(df: pd.DataFrame, columns: Union[str, List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove all rows containing missing values either from the whole DataFrame or from specific columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        columns (Union[str, List[str]], optional): Column or list of columns to consider for row removal.\n",
    "                                                   If None, consider all columns. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with rows containing missing values removed.\n",
    "    \"\"\"\n",
    "\n",
    "    if columns is not None:\n",
    "        return df.dropna(subset=columns)\n",
    "    else:\n",
    "        return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _remove_rows_with_missing_values(df: pd.DataFrame, columns: Union[str, List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove all rows containing missing values either from the whole DataFrame or from specific columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        columns (Union[str, List[str]], optional): Column or list of columns to consider for row removal.\n",
    "                                                   If None, consider all columns. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with rows containing missing values removed.\n",
    "    \"\"\"\n",
    "\n",
    "    if columns is not None:\n",
    "        return df.dropna(subset=columns)\n",
    "    else:\n",
    "        return df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "def _remove_outliers_isolation_forest(df: pd.DataFrame, contamination: float = 0.2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove outliers using the Isolation Forest algorithm.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with numerical columns.\n",
    "        contamination (float): Proportion of outliers in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Initialize the IsolationForest model\n",
    "    clf = IsolationForest(contamination=contamination)\n",
    "\n",
    "    # Fit the model on numerical columns\n",
    "    clf.fit(df[numerical_cols])\n",
    "\n",
    "    # Get outlier predictions\n",
    "    outlier_predictions = clf.predict(df[numerical_cols])\n",
    "\n",
    "    # Remove outliers from the original DataFrame based on the predictions\n",
    "    df_filtered = df[outlier_predictions == 1]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame, parameters: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses data.\n",
    "\n",
    "    Args:\n",
    "        data: Raw data.\n",
    "\n",
    "    Returns:\n",
    "        Preprocessed data, with missing values removed.\n",
    "    \"\"\"\n",
    "    features_and_target = parameters[\"features\"] + parameters[\"target\"]\n",
    "    df = data[features_and_target]\n",
    "    df = _remove_rows_with_missing_values(df)\n",
    "    df = _remove_outliers_isolation_forest(df)\n",
    "    preprocessed_data = df\n",
    "\n",
    "    return preprocessed_data\n",
    "\n",
    "\n",
    "def _remap_industry(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    industries_to_keep = df['Industry (Exiobase)'].value_counts()[df['Industry (Exiobase)'].value_counts() > 50].index\n",
    "    df['Industry (Exiobase)'] = df['Industry (Exiobase)'].apply(lambda x: x if x in industries_to_keep else 'Other')\n",
    "    return df\n",
    "\n",
    "\n",
    "def _create_interaction_terms(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    interaction_pairs = [\n",
    "        ('Use of Sold Products', 'Processing of Sold Products'),\n",
    "        ('Use of Sold Products', 'Purchased Goods and Services'),\n",
    "        ('Processing of Sold Products', 'Purchased Goods and Services'),\n",
    "        ('Purchased Goods and Services', 'End of Life Treatment of Sold Products')\n",
    "    ]\n",
    "\n",
    "    for col1, col2 in interaction_pairs:\n",
    "        new_col_name = f\"{col1}_x_{col2}\"\n",
    "        df[new_col_name] = df[col1] * df[col2]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _create_polynomial_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols_to_square = [\n",
    "        'Use of Sold Products',\n",
    "        'Processing of Sold Products',\n",
    "        'Purchased Goods and Services',\n",
    "        'End of Life Treatment of Sold Products'\n",
    "    ]\n",
    "\n",
    "    for col in cols_to_square:\n",
    "        new_col_name = f\"{col}_Squared\"\n",
    "        df[new_col_name] = df[col] ** 2\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _one_hot_encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # One-hot encode 'Country' and 'Industry (Exiobase)' columns\n",
    "    df_encoded = pd.get_dummies(df, columns=['Industry (Exiobase)'])\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "def _normalization(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create the scaler\n",
    "    scaler_standard = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to the data (excluding categorical data if not already encoded)\n",
    "    df_normalized_standard = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    return df_normalized_standard\n",
    "\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Conducts feature engineering on the given DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    1. Outlier Removal: Removes outliers using the Isolation Forest algorithm.\n",
    "    2. Remap Industry: Aggregates less frequent industry categories into 'Other'.\n",
    "    3. Create Interaction Terms: Creates new features by multiplying pairs of existing features.\n",
    "    4. Create Polynomial Features: Squares selected features to create new polynomial features.\n",
    "    5. One-Hot Encoding: One-hot encodes categorical features.\n",
    "    6. Normalization: Standardizes the feature values.\n",
    "\n",
    "    Args:\n",
    "        df: Original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        df_feature_engineered: DataFrame after feature engineering.\n",
    "    \"\"\"\n",
    "\n",
    "    # df = _outlier_removal(df)\n",
    "    df = _remap_industry(df)\n",
    "    df = _create_interaction_terms(df)\n",
    "    df = _create_polynomial_features(df)\n",
    "    df = _one_hot_encode(df)\n",
    "    df = _normalization(df)\n",
    "    df_feature_engineered = df\n",
    "\n",
    "    return df_feature_engineered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
