{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "1. Create ML Model based on this dataset\n",
    "2. Create models for specific industries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Structure:\n",
    "1. Abstract\n",
    "2. Data collection\n",
    "3. Preprocess data\n",
    "4. Feature engineering\n",
    "5. Train, test split\n",
    "6. Modelling\n",
    "7. Model evaluation\n",
    "8. Hyperparameter tuning \n",
    "9. Model Interpretation \n",
    "10. Results and conclusions\n",
    "11. References and Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Abstract "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Predicting Scope 3 Emissions using Machine Learning: A Novel Approach\n",
    "\n",
    "The following research of mine is based on a study conducted by Serafeim, George and Velez Caicedo, Gladys. 2022. \"Machine Learning Models for Prediction of Scope 3 Carbon Emissions.\" Harvard Business School Working Paper, 2022.\n",
    "\n",
    "I would like to thank the authors for sharing their methodology and data, which allows me to independently conduct research and modeling and then compare the results with the conclusions of the researchers thanks to which I have a great opportunity to learn and to lead the research in new directions by updating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Guidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2022 by George Serafeim and Gladys Velez Caicedo. \"Machine Learning Models for Prediction of Scope 3 Carbon Emissions.\" Harvard Business School Working Paper, 2022\t\t\n",
    "Funding for this research was provided in part by Harvard Business School.\t\t\n",
    "\t\t\n",
    "Data source: \t\t\n",
    "“Serafeim, George and Velez Caicedo, Gladys. 2022. \"Machine Learning Models for Prediction of Scope 3 Carbon Emissions.\" Harvard Business School Working Paper, 2022\t\t\n",
    "\t\t\n",
    "GUIDANCE:\t\t\n",
    "Column A \"Year\" is the year in which the environmental impact was incurred by the firm's operations.\t\t\n",
    "\t\t\n",
    "Column B \"Company Name\" is the name of the issuer.\t\t\n",
    "\t\t\n",
    "Column C \"Country\" is the country in which the companies' headquarters are located.\t\t\n",
    "\t\t\n",
    "Column D \"Industry\" refers to the Exiobase industry category to which the firm belongs: We provide only the Exiobase industries here as they are open source, but in our paper, we use GICS taxonomy as fixed effects.\t\t\n",
    "All Exiobase industries are based on the International Standard Industrial Classification Revision 3.1 (ISIC). \tTo learn more about ISIC and a comprehensive list of industries included, please refer to: unstats.un.org/unsd/statcom/doc02/isic.pdf\t\n",
    "\tFor example, the term \"nec\" refers to \"not elsewhere classified.\"\t\n",
    "\t\t\n",
    "Column E \"GHG Intensity (Sales)\" is the monetized GHG impact of the firm's operations during the specific year indicated in column A divided by revenue in that year\t\t\n",
    "\t\t\n",
    "Column F \"GHG Intensity (Op Inc)\" is the monetized GHG impact of the firm's operations during the specific year indicated in column A divided by operating income in that year\t\t\n",
    "\t\t\n",
    "Column G \"Total GHG Environmental Cost (Scope 1, 2, 3) \" is the total monetized GHG environmental impact of Scope 1, 2, and 3 emissions of the firm's operations during the specific year indicated in Column A.\t\t\n",
    "\t\t\n",
    "Columns H-J are Scope 1, 2, 3 Emissions\t\t\n",
    "Each scope of emissions is defined by the GHG Protocol. More information can be found at the Greenhouse Gas Protocol: https://ghgprotocol.org/\t\t\n",
    "\tColumn H:\t Scope 1 Emissions: emissions from direct operations that occur from sources that are controlled or owned by the firm \n",
    "\tColumn I:\t Scope 2 Emissions: emissions associated with the purchase of electricity, steam, heat, or cooling as a result of the firm's energy use \n",
    "\tColumn J:\t Scope 3 Emissions: emissions from 15 categories that are result of activities from assets not owned or controlled by the reporting firm, not within a firm's scope 1 and 2 boundary and occur through the value chain. \n",
    "\t\t\n",
    "Columns K-BC are fiveteen Scope 3 emissions category types in alphabetical order followed by an indicator variable denoting if the data point is company reported (0) or if the data point is predicted via machine learning (1)\t\t\n",
    "\tColumn K\tBusiness Travel\n",
    "\tColumn N:\tCapital Goods\n",
    "\tColumn Q:\tDownstream Leased Assets\n",
    "\tColumn T:\tDownstream Transportation and Distribution\n",
    "\tColumn W:\tEmployee Commuting\n",
    "\tColumn Z:\tEnd of Life Treatment of Sold Products\n",
    "\tColumn AC:\tFranchises\n",
    "\tColumn AF:\tFuel-and-energy-related activities (not included in Scope 1 or 2)\n",
    "\tColumn AI:\tInvestments\n",
    "\tColumn AL:\tProcessing of Sold Products\n",
    "\tColumn AO:\tPurchased Goods and Services\n",
    "\tColumn AR:\tUpstream Leased Assets\n",
    "\tColumn AU:\tUpstream Transportation and Distribution\n",
    "\tColumn AX:\tUse of Sold Products\n",
    "\tColumn BA:\tWaste Generated in Operations\n",
    "\t\t\n",
    "The dataset is a combination of primary firm reported emissions data supplemented with Scope 3 predictions by category.\t\t\n",
    "Our methodology takes firm reported values first and incorporates imputations only when companies' self-reported emissions data are not publicly available.\t\t\n",
    "If the data point is imputed, the Scope 3 category \"Imputed\" value is 1.\t\t\n",
    "If the data point is company reported, the Scope 3 category \"Imputed\" value is 0.\t\t\n",
    "The Scope 3 category \"Test\" column indicates if the data point was used to \"train\" or \"test\" the machine learning model. If no company value is reported, the value. Is set to \"none\". \t\t\n",
    "\t\t\n",
    "Other Notes:\t\t\n",
    "The \"Final Raw Sample(0%)\" tab includes all raw outputs, discounted at 0%, from our environmental impact calculation methodology. The Social Cost of Carbon discounted at 0% applied here is roughly $300 USD per metric ton of emissions.\t\t\n",
    "The \"Final Raw Sample(3%)\" tab includes all raw outputs, discounted at 3%, from our environmental impact calculation methodology. The Social Cost of Carbon discounted at 3% applied here is roughly $100 USD per metric ton of emissions.\t\t\n",
    "All observations in the tabs are sorted by 1) Year in descending order, 2) Industry in alphabetical order, and 3) Environmental Intensity (Sales) in descending order.\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "Also, if you are a researcher planning to use the data in an academic research project, please email us and we will send you a file including ISINs to facilitate merging with other datasets.\t\t\n",
    "Our team can be reached at: ImpactWeightedAccounts@hbs.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data cllection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainging dataset\n",
    "df = pl.read_excel(\n",
    "    \"../data/01_raw/IWA-External-Scope-3-Data.xlsx\",\n",
    "    sheet_name=\"3%\",\n",
    ")\n",
    "\n",
    "# 3% tab includes all raw outputs, discounted at 3%, from our environmental impact calculation methodology. \n",
    "# The Social Cost of Carbon discounted at 3% applied here is roughly $100 USD per metric ton of emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with 0% rate\n",
    "\n",
    "df_0_percent = pl.read_excel(\n",
    "    \"../data/01_raw/IWA-External-Scope-3-Data.xlsx\",\n",
    "    sheet_name=\"0%\",\n",
    ")\n",
    "\n",
    "# 0% tab includes all raw outputs, discounted at 0%, from our environmental impact calculation methodology. \n",
    "# The Social Cost of Carbon discounted at 0% applied here is roughly $300 USD per metric ton of emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AI Agent for EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. AI suggestions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable scaling in preprocessing phase \n",
    "# Time series analysis at the end of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data types and structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data types\n",
    "def check_data_types(df):\n",
    "    data_types = df.dtypes.value_counts()\n",
    "    return data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    21\n",
       "object     18\n",
       "int64      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data_types(df_eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First missing values are in GHG Intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used in preprocessing \n",
    "def _is_true(x: pd.Series) -> pd.Series:\n",
    "    return x == \"t\"\n",
    "\n",
    "\n",
    "def _parse_percentage(x: pd.Series) -> pd.Series:\n",
    "    x = x.str.replace(\"%\", \"\")\n",
    "    x = x.astype(float) / 100\n",
    "    return x\n",
    "\n",
    "# Template function which will be implement to data_prcessing pipeline to nodes.py \n",
    "def preprocess_companies(companies: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses the data for companies.\n",
    "\n",
    "    Args:\n",
    "        companies: Raw data.\n",
    "    Returns:\n",
    "        Preprocessed data, with `company_rating` converted to a float and\n",
    "        `iata_approved` converted to boolean.\n",
    "    \"\"\"\n",
    "    companies[\"iata_approved\"] = _is_true(companies[\"iata_approved\"])\n",
    "    companies[\"company_rating\"] = _parse_percentage(companies[\"company_rating\"])\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for function used for splitting data in data_science pipeline in nodes.py \n",
    "def split_data(data: pd.DataFrame, parameters: Dict) -> Tuple:\n",
    "    \"\"\"Splits data into features and targets training and test sets.\n",
    "\n",
    "    Args:\n",
    "        data: Data containing features and target.\n",
    "        parameters: Parameters defined in parameters/data_science.yml.\n",
    "    Returns:\n",
    "        Split data.\n",
    "    \"\"\"\n",
    "    X = data[parameters[\"features\"]]\n",
    "    y = data[\"price\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for function used for training in data_science pipeline in nodes.py\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> LinearRegression:\n",
    "    \"\"\"Trains the linear regression model.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training data of independent features.\n",
    "        y_train: Training data for price.\n",
    "\n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    regressor = LinearRegression()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for function used for model evalution in data_science pipeline in nodes.py \n",
    "def evaluate_model(\n",
    "    regressor: LinearRegression, X_test: pd.DataFrame, y_test: pd.Series\n",
    "):\n",
    "    \"\"\"Calculates and logs the coefficient of determination.\n",
    "\n",
    "    Args:\n",
    "        regressor: Trained model.\n",
    "        X_test: Testing data of independent features.\n",
    "        y_test: Testing data for price.\n",
    "    \"\"\"\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(\"Model has a coefficient R^2 of %.3f on test data.\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DALSZE MODELOWANIE\n",
    "# MODELOWANIE DLA FIRM Z TYCH SAMYCH BRANZ, lub kilku podobnych branz\n",
    "# MODELOWANIE DLA FIRM O PODOBNEJ CHARAKTERYSTYCE PROCESOW, DZIALANOSCI,\n",
    "# MODELOWANIE DLA DANYCH KONTYNENTOW "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
