{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "1.\n",
    "2.\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Structure:\n",
    "1. Abstract\n",
    "2. Load data\n",
    "3. EDA\n",
    "4. Preprocess data\n",
    "5. Feature engineering\n",
    "6. Train, test split\n",
    "7. Modelling\n",
    "8. Model evaluation\n",
    "9. Hyperparameter tuning \n",
    "10. Model Interpretation \n",
    "11. Results and conclusions\n",
    "12. References and Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My building blocks for modeling \n",
    "## - EDA\n",
    "## - Preprocessing\n",
    "## - Feature engineering \n",
    "## - Training\n",
    "## - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole raw data\n",
    "df = catalog.load(\"data_from_catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = catalog.load(\"params:feature_options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only features which are define in ../conf/base/parameters/...\n",
    "df = df[parameters[\"features\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profiling(df: pd.DataFrame, name: str=\"data_profiling_report\", interface: str=\"html\") -> None:\n",
    "  \"\"\"\n",
    "  This function generates a data profiling report using the pandas_profiling package.\n",
    "  \n",
    "  Args:\n",
    "      df (pd.DataFrame): The DataFrame to profile.\n",
    "      name (str, optional): The title of the profile report. Defaults to \"data_profiling_report\".\n",
    "      interface (str, optional): The format of the report. Defaults to \"html\".\n",
    "                                  Choose between 'html' or 'widget'.\n",
    "  \n",
    "  Raises:\n",
    "      ValueError: If df is not a pandas DataFrame or name is not a string or \n",
    "                  if interface is not 'html' or 'widget'\n",
    "  \"\"\"\n",
    "  \n",
    "  # Check if df is a pandas DataFrame\n",
    "  if not isinstance(df, pd.DataFrame):\n",
    "    raise ValueError(\"df should be a pandas DataFrame\")\n",
    "    \n",
    "  # Check if name is a string\n",
    "  if not isinstance(name, str):\n",
    "    raise ValueError(\"name should be a string\")\n",
    "  \n",
    "  # Check if interface is a string and a valid option\n",
    "  if not isinstance(interface, str) or interface not in ['html', 'widget']:\n",
    "    raise ValueError(\"interface should be a string, either 'html' or 'widget'\")\n",
    "  \n",
    "  profile = ProfileReport(df, title=name, explorative=True)\n",
    "\n",
    "  if interface == \"html\":\n",
    "    profile.to_file(f\"{name}.html\")\n",
    "    logging.info(f\"Report {name} generated in html format, check files.\")\n",
    "    \n",
    "  elif interface == \"widget\":\n",
    "    logging.info(f\"Report {name} will be generated as a widget, it might take a while.\")\n",
    "    profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data profiling report in HTML format\n",
    "# data_profiling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "missing_values_per_column = df.isna().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values_per_column)\n",
    "\n",
    "# Count total missing values in the DataFrame\n",
    "total_missing_values = df.isna().sum().sum()\n",
    "print(f\"Total missing values: {total_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "def _remove_rows_with_missing_values(df: pd.DataFrame, columns: Union[str, List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove all rows containing missing values either from the whole DataFrame or from specific columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        columns (Union[str, List[str]], optional): Column or list of columns to consider for row removal. \n",
    "                                                   If None, consider all columns. Default is None.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with rows containing missing values removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if columns is not None:\n",
    "        return df.dropna(subset=columns)\n",
    "    else:\n",
    "        return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values from whole DataFrame\n",
    "# df = _remove_rows_with_missing_values(df)\n",
    "\n",
    "# Remove rows with missing values only from columns A and B\n",
    "# df = _remove_rows_with_missing_values(df, columns=['A', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple impution with mean, median or zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "def _impute_missing_values(df: pd.DataFrame, columns: Union[List[str], str], strategy: str = 'mean') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Impute missing values in specific columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        columns (Union[List[str], str]): Column or columns in which to impute missing values.\n",
    "        strategy (str, optional): The imputation strategy. Options are 'mean', 'median', 'mode', and 'zero'. Defaults to 'mean'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed in the specified columns.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(columns, list):\n",
    "        columns = [columns]\n",
    "        \n",
    "    for column in columns:\n",
    "        if strategy == 'mean':\n",
    "            df[column].fillna(df[column].mean(), inplace=True)\n",
    "        elif strategy == 'median':\n",
    "            df[column].fillna(df[column].median(), inplace=True)\n",
    "        elif strategy == 'mode':\n",
    "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "        elif strategy == 'zero':\n",
    "            df[column].fillna(0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 df_imputed = _impute_missing_values(df.copy(), [<span style=\"color: #808000; text-decoration-color: #808000\">'A'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">'B'</span>], <span style=\"color: #808000; text-decoration-color: #808000\">'mean'</span>)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'_impute_missing_values'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 df_imputed = _impute_missing_values(df.copy(), [\u001b[33m'\u001b[0m\u001b[33mA\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33mB\u001b[0m\u001b[33m'\u001b[0m], \u001b[33m'\u001b[0m\u001b[33mmean\u001b[0m\u001b[33m'\u001b[0m)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'_impute_missing_values'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Impute missing values in columns 'A' and 'B' using the 'mean' strategy\n",
    "# df_imputed = _impute_missing_values(df.copy(), ['A', 'B'], 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def regression_impute(df: pd.DataFrame, target_column: str, feature_columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Impute missing values in a target column using regression on feature columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        target_column (str): The column in which to impute missing values.\n",
    "        feature_columns (list): List of feature columns to use for imputation.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed in the target column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create separate dataframes for rows with missing and non-missing target values\n",
    "    df_missing = df[df[target_column].isna()]\n",
    "    df_not_missing = df.dropna(subset=[target_column])\n",
    "    \n",
    "    # Separate features and target for rows without missing target values\n",
    "    X_train = df_not_missing[feature_columns]\n",
    "    y_train = df_not_missing[target_column]\n",
    "    \n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict target values for rows with missing target values\n",
    "    X_missing = df_missing[feature_columns]\n",
    "    y_pred = model.predict(X_missing)\n",
    "    \n",
    "    # Impute the predicted values back into the original dataframe\n",
    "    df.loc[df[target_column].isna(), target_column] = y_pred\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assume df is your DataFrame, 'age' is the column with missing values and ['income', 'education'] are features.\n",
    "# df = regression_impute(df, 'age', ['income', 'education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">sklearn.ensemble</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> IsolationForest                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 3 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">remove_outliers_isolation_forest</span>(df: pd.DataFrame, contamination: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">float</span> = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.2</span>) -&gt; pd    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Remove outliers using the Isolation Forest algorithm.</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'pd'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msklearn\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mensemble\u001b[0m \u001b[94mimport\u001b[0m IsolationForest                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 3 \u001b[94mdef\u001b[0m \u001b[92mremove_outliers_isolation_forest\u001b[0m(df: pd.DataFrame, contamination: \u001b[96mfloat\u001b[0m = \u001b[94m0.2\u001b[0m) -> pd    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mRemove outliers using the Isolation Forest algorithm.\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'pd'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def remove_outliers_isolation_forest(df: pd.DataFrame, contamination: float = 0.2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove outliers using the Isolation Forest algorithm.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with numerical columns.\n",
    "        contamination (float): Proportion of outliers in the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Initialize the IsolationForest model\n",
    "    clf = IsolationForest(contamination=contamination) \n",
    "\n",
    "    # Fit the model on numerical columns\n",
    "    clf.fit(df[numerical_cols])\n",
    "\n",
    "    # Get outlier predictions\n",
    "    outlier_predictions = clf.predict(df[numerical_cols])\n",
    "\n",
    "    # Remove outliers from the original DataFrame based on the predictions\n",
    "    df_filtered = df[outlier_predictions == 1]\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame, parameters: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses data.\n",
    "\n",
    "    Args:\n",
    "        data: Raw data.\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed data, with missing values removed.\n",
    "    \"\"\"\n",
    "    # Example\n",
    "    df = data[parameters[\"features\"]]\n",
    "    df = _remove_missing_values(df)\n",
    "    preprocessed_data = df\n",
    "    \n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = preprocess_scope3(df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_hot_encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # One-hot encode 'Country' and 'Industry (Exiobase)' columns\n",
    "    df_encoded = pd.get_dummies(df, columns=['Industry (Exiobase)'])\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization/Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalization(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create the scaler\n",
    "    scaler_standard = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to the data (excluding categorical data if not already encoded)\n",
    "    df_normalized_standard = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)\n",
    "    \n",
    "    return df_normalized_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Conducts feature engineering on the given DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    1. One-Hot Encoding: One-hot encodes categorical features.\n",
    "    2. Normalization: Standardizes the feature values.\n",
    "    ...\n",
    "\n",
    "    Args:\n",
    "        df: Original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        df_feature_engineered: DataFrame after feature engineering.\n",
    "    \"\"\"\n",
    "\n",
    "    df = _one_hot_encode(df)\n",
    "    df = _normalization(df)\n",
    "    df_feature_engineered = df\n",
    "\n",
    "    return df_feature_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_engineered = feature_engineering(preprocessed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame, model_options: Dict) -> Tuple:\n",
    "    \"\"\"Splits data into features and targets training and test sets.\n",
    "\n",
    "    Args:\n",
    "        data: Data containing features and target.\n",
    "        parameters: Parameters defined in parameters/data_science.yml.\n",
    "    Returns:\n",
    "        Split data.\n",
    "    \"\"\"\n",
    "    # X = data[parameters[\"features\"]]\n",
    "    X = data[parameters[\"features\"]].drop(\"Scope 3\", axis=1)\n",
    "    y = data[\"Scope 3\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = catalog.load(\"params:model_options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_feature_engineered is your DataFrame and parameters is your configuration dictionary\n",
    "X_train, X_test, y_train, y_test = split_data(df_feature_engineered, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> Any:\n",
    "    \"\"\"Trains the XGBoost model.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training data of independent features.\n",
    "        y_train: Training data for target variable.\n",
    "        \n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'alpha': 9.418025790529975e-05,\n",
    "        'colsample_bytree': 0.73850137825373,\n",
    "        'eta': 0.03756810920990241,\n",
    "        'gamma': 1.8103086083962833e-05,\n",
    "        'lambda': 0.006052853661670603,\n",
    "        'max_depth': 4,\n",
    "        'min_child_weight': 1.0000000000000004e-06,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'subsample': 0.8954379516782436,\n",
    "        'eval_metric': ['rmse', 'mae']\n",
    "    }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=674)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    \"\"\"Calculates and logs the coefficient of determination and RMSE.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained XGBoost model.\n",
    "        X_test: Testing data of independent features.\n",
    "        y_test: Testing data for target variable.\n",
    "    \"\"\"\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    y_pred = model.predict(dtest)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    print(f\"Model has a coefficient R^2 of {score:.3f} on test data.\")\n",
    "    print(f\"Model has a RMSE of {rmse:.3f} on test data.\")\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"Model has a coefficient R^2 of {score:.3f} on test data.\")\n",
    "    logger.info(f\"Model has a RMSE of {rmse:.3f} on test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_model(trained_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Acknowledgments\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (scope_3_emissions_prediction)",
   "language": "python",
   "name": "kedro_scope_3_emissions_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
