{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "1.\n",
    "2.\n",
    "3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Structure:\n",
    "1. Abstract\n",
    "2. Load data\n",
    "3. EDA\n",
    "4. Preprocess data\n",
    "5. Feature engineering\n",
    "6. Train, test split\n",
    "7. Modelling\n",
    "8. Model evaluation\n",
    "9. Hyperparameter tuning \n",
    "10. Model Interpretation \n",
    "11. Results and conclusions\n",
    "12. References and Acknowledgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = catalog.load(\"data_from_catalog\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_profiling(df: pd.DataFrame, name: str=\"data_profiling_report\", interface: str=\"html\") -> None:\n",
    "  \"\"\"\n",
    "  This function generates a data profiling report using the pandas_profiling package.\n",
    "  \n",
    "  Args:\n",
    "      df (pd.DataFrame): The DataFrame to profile.\n",
    "      name (str, optional): The title of the profile report. Defaults to \"data_profiling_report\".\n",
    "      interface (str, optional): The format of the report. Defaults to \"html\".\n",
    "                                  Choose between 'html' or 'widget'.\n",
    "  \n",
    "  Raises:\n",
    "      ValueError: If df is not a pandas DataFrame or name is not a string or \n",
    "                  if interface is not 'html' or 'widget'\n",
    "  \"\"\"\n",
    "  \n",
    "  # Check if df is a pandas DataFrame\n",
    "  if not isinstance(df, pd.DataFrame):\n",
    "    raise ValueError(\"df should be a pandas DataFrame\")\n",
    "    \n",
    "  # Check if name is a string\n",
    "  if not isinstance(name, str):\n",
    "    raise ValueError(\"name should be a string\")\n",
    "  \n",
    "  # Check if interface is a string and a valid option\n",
    "  if not isinstance(interface, str) or interface not in ['html', 'widget']:\n",
    "    raise ValueError(\"interface should be a string, either 'html' or 'widget'\")\n",
    "  \n",
    "  profile = ProfileReport(df, title=name, explorative=True)\n",
    "\n",
    "  if interface == \"html\":\n",
    "    profile.to_file(f\"{name}.html\")\n",
    "    logging.info(f\"Report {name} generated in html format, check files.\")\n",
    "    \n",
    "  elif interface == \"widget\":\n",
    "    logging.info(f\"Report {name} will be generated as a widget, it might take a while.\")\n",
    "    profile.to_widgets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to remove all rows with missing values in a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input pandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Output DataFrame with rows containing missing values removed.\n",
    "    \"\"\"\n",
    "\n",
    "    df_cleaned = df.dropna()\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _outlier_removal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Identify numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # Initialize the IsolationForest model\n",
    "    clf = IsolationForest(contamination=0.2)  # contamination: proportion of outliers in the data set\n",
    "\n",
    "    # Fit the model on numerical columns\n",
    "    clf.fit(df[numerical_cols])\n",
    "\n",
    "    # Get outlier predictions\n",
    "    outlier_predictions = clf.predict(df[numerical_cols])\n",
    "\n",
    "    # Remove outliers from the original DataFrame based on the predictions\n",
    "    df_filtered = df[outlier_predictions == 1]\n",
    "\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data: pd.DataFrame, parameters: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses data.\n",
    "\n",
    "    Args:\n",
    "        data: Raw data.\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed data, with missing values removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = data[parameters[\"features\"]]\n",
    "    df = _remove_missing_values(df)\n",
    "    preprocessed_data = df\n",
    "    \n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = preprocess_scope3(df, features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_hot_encode(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # One-hot encode 'Country' and 'Industry (Exiobase)' columns\n",
    "    df_encoded = pd.get_dummies(df, columns=['Industry (Exiobase)'])\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization/Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalization(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create the scaler\n",
    "    scaler_standard = StandardScaler()\n",
    "\n",
    "    # Fit the scaler to the data (excluding categorical data if not already encoded)\n",
    "    df_normalized_standard = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)\n",
    "    \n",
    "    return df_normalized_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Conducts feature engineering on the given DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    1. One-Hot Encoding: One-hot encodes categorical features.\n",
    "    2. Normalization: Standardizes the feature values.\n",
    "    ...\n",
    "\n",
    "    Args:\n",
    "        df: Original DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        df_feature_engineered: DataFrame after feature engineering.\n",
    "    \"\"\"\n",
    "\n",
    "    df = _one_hot_encode(df)\n",
    "    df = _normalization(df)\n",
    "    df_feature_engineered = df\n",
    "\n",
    "    return df_feature_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_engineered = feature_engineering(preprocessed_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data: pd.DataFrame, model_options: Dict) -> Tuple:\n",
    "    \"\"\"Splits data into features and targets training and test sets.\n",
    "\n",
    "    Args:\n",
    "        data: Data containing features and target.\n",
    "        parameters: Parameters defined in parameters/data_science.yml.\n",
    "    Returns:\n",
    "        Split data.\n",
    "    \"\"\"\n",
    "    # X = data[parameters[\"features\"]]\n",
    "    X = data[parameters[\"features\"]].drop(\"Scope 3\", axis=1)\n",
    "    y = data[\"Scope 3\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=parameters[\"test_size\"], random_state=parameters[\"random_state\"]\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = catalog.load(\"params:model_options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_feature_engineered is your DataFrame and parameters is your configuration dictionary\n",
    "X_train, X_test, y_train, y_test = split_data(df_feature_engineered, parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> Any:\n",
    "    \"\"\"Trains the XGBoost model.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training data of independent features.\n",
    "        y_train: Training data for target variable.\n",
    "        \n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'alpha': 9.418025790529975e-05,\n",
    "        'colsample_bytree': 0.73850137825373,\n",
    "        'eta': 0.03756810920990241,\n",
    "        'gamma': 1.8103086083962833e-05,\n",
    "        'lambda': 0.006052853661670603,\n",
    "        'max_depth': 4,\n",
    "        'min_child_weight': 1.0000000000000004e-06,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'subsample': 0.8954379516782436,\n",
    "        'eval_metric': ['rmse', 'mae']\n",
    "    }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    model = xgb.train(params, dtrain, num_boost_round=674)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: Any, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    \"\"\"Calculates and logs the coefficient of determination and RMSE.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained XGBoost model.\n",
    "        X_test: Testing data of independent features.\n",
    "        y_test: Testing data for target variable.\n",
    "    \"\"\"\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    y_pred = model.predict(dtest)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    print(f\"Model has a coefficient R^2 of {score:.3f} on test data.\")\n",
    "    print(f\"Model has a RMSE of {rmse:.3f} on test data.\")\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(f\"Model has a coefficient R^2 of {score:.3f} on test data.\")\n",
    "    logger.info(f\"Model has a RMSE of {rmse:.3f} on test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluate_model(trained_model, X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Acknowledgments\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
